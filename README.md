# student_course_work
Repository for coursework completed for BSc Computing and IT
Examples to be added to this repo once the 2019/20 academic year is finished.

# Interaction Design and User Experience
This includes my designs for a hardware device and the supporting software application, for a system supporting the playback of online video content.

# About the designs
The interactive product comprises a wireless keyboard fitted with a trackball and supporting software. The device supports the activity of accessing and playing back videos on a compatible computer system (e.g. a laptop running Microsoft Windows) used with an internet browser and a third-party video service introducing convenience and flexibility the user otherwise does not have. 

The hardware supports typing web addresses and search terms to locate videos accessed on a web page. The trackball is used as a pointing device (e.g. to click on hyperlinks to videos). The software supports context driven lighting of media playback keys to match the controls active in the video player, carries out browser and webcam monitoring and automatically pauses videos in selected situations. 

Users of this new product will be educated to at least secondary level with some digital skills and familiarity navigating video players and browsers on laptop or desktop computers. Users will have sufficient vision and hearing with or without aids to watch videos. Users could have varying levels of manual dexterity. 

The typical environment where the device will be used will be a home environment, where the user can control the light levels of the room and choose a quiet area in which to watch and listen to video media. 


I also include some extracts below from my written report, indicating what I learned during evaluation, and how well different evaluation methods worked.

# Recommendations for improvement
# Hardware
Further research is required to determine how best to support users for controlling the on-screen pointer. To support different dexterity capabilities of users, a modular space allowing connection of the user’s choice of mouse or trackball could be a solution to explore. However, the convenience of having media keys located close by the controller would ideally not be lost.

# Software
A guided set-up would be a solution to help prevent users from forgetting to select browsers, services and auto pause support. During a guided set up the web cam monitoring could be offered whilst advising how it will work, reassuring the users of how their privacy would be protected.

# The Evaluation
# What worked well
The think aloud method provided opinions specific to the tasks of setting up the Companion App for use and using the Media Board keyboard to access an online video. The interview yielded more general opinions about the device. Specific but open questions were put to the participants, which yielded detailed insights. This led to some discussions about privacy and security which went beyond the scope of what this project intended. Another discovery was participants expecting more from the device than it would deliver.

# What worked less well
Counting steps taken in the scenarios was not helpful and attempting to draw conclusions from the quantitative data is problematic for the following reasons:
1.	The low fidelity designs cannot be interacted with in such a way that all users could accurately demonstrate their actions. Participants used variable levels of precision when describing the steps they would take. 
2.	Capturing every user step was a challenge without the ability to record dialogue or users pointing to features on screen, because it is difficult to observe pointing on screen while making handwritten notes.

# What could be done differently
If unable to use recordings because participants do not grant permission there are other ways of monitoring steps taken through a scenario. Precise counts of steps could be acquired by using an interactive mock-up (for e.g, an HTML web page could be provided to users to simulate interaction). Interactions with the mock-up could be observed by a researcher, or software could log user actions.
Alternatively, quantitative data could be collected by asking participants to record their own steps through scenarios. Surveying participants would not invade participants’ personal space. Strict instructions could request each navigation, click and text entering action.
More questions could be asked in a survey or interview regarding which of the features of the physical and graphical user interfaces users liked and how users may choose to use those features. This would give more qualitative data.

